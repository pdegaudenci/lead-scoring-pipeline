# Lead Scoring Pipeline

## üìã Objetivo del Proyecto

Crear una soluci√≥n que reciba datos de leads, realice una puntuaci√≥n (**scoring**) utilizando un modelo simple y almacene los resultados de manera estructurada en Snowflake. Esto incluye la ingesta de datos desde S3 (, el procesamiento del scoring y la automatizaci√≥n de la carga de datos.

---

## üìà Iterative Development ‚Äì Sprints Overview (üìÖ Agile Sprint Plan). 2 D√≠as

### Sprint 1 - Procesamiento de Leads

#### Funcionalidades Implementadas

1. **Carga de Archivos CSV y JSON**
   - Procesamiento de archivos CSV para convertirlos a formato JSON.
   - Manejo de valores nulos y limpieza de datos para asegurar la integridad.
   - Generaci√≥n de archivos JSON y carga a Snowflake mediante stages internos.

2. **Optimizaci√≥n del Pipeline**
   - Ajustes en el formato de archivos para evitar problemas de formato (.json.gz).
   - Implementaci√≥n de scripts para manejar errores de datos y compatibilidad.

3. **Validaci√≥n de Archivos en Snowflake**
   - Procedimientos almacenados para validar la estructura de archivos antes de cargar.
   - Scripts para verificar la existencia de columnas y filas antes de insertar datos.
   - Pruebas en IU de Snowflake.

#### Consideraciones T√©cnicas para la Carga y Procesamiento de Datos

1. **Separaci√≥n de Tablas**
   - leads_raw: tabla intermedia que almacena los datos en formato JSON crudo.
   - leads_final: tabla destino con los datos desplegados en columnas estructuradas.

2. **Carga Incremental**
   - Comparaci√≥n por identificadores √∫nicos como Prospect_ID.
   - Uso de campos de fecha de actualizaci√≥n o generaci√≥n de hash/checksum.

3. **Automatizaci√≥n del Flujo**
   - **Procedimientos Almacenados (PA):** l√≥gica de validaci√≥n de ficheros y creacion de tabla a partir de estructura de fichero JSON cargado en internal stage
   - **TASK:** Carga datos en tabla leads_final.
   - **STREAMs:** detectan nuevos registros en tabla leads_raw y activa task de carga en tabla final.
   - **Snowpipe:** automatiza la ingesta continua.

> Estas consideraciones permitir√°n escalar el pipeline de forma robusta, controlada y optimizada para entornos de producci√≥n.

#### Problemas Encontrados

- **Errores de Compresi√≥n y Formato**
  - Archivos subidos como .json.gz causaban errores.
  - Configuraci√≥n corregida para evitar errores de conteo de filas y columnas.
  - Snowflake renombraba autom√°ticamente los archivos, dificultando su carga con COPY INTO.

- **Errores en Procedimientos Almacenados**
  - Ajustes de sintaxis y l√≥gica en procedimientos.
  - Mejor manejo de excepciones y mensajes de error.

- **Configuraci√≥n de FastAPI**
  - Archivos mal subidos por configuraciones incorrectas.
  - Ajuste de rutas para evitar subcarpetas en stages.

#### Soluciones Aplicadas

- Validaci√≥n desde Snowflake SQL worksheet.
- Conversi√≥n de JSON a NDJSON.
- Eliminaci√≥n de compresi√≥n innecesaria.
- Captura del nombre renombrado con UUID tras el comando PUT.
- Ruta correcta en PUT y COPY INTO. Finalmente, se opta por el siguiente flujo de datos : Snowpipe carga en leads_raw  datos de JSON‚Üí (detected by STREAM) ‚Üí TASK ‚Üí inserta en leads_finalleads_raw ‚Üí (detected by STREAM) ‚Üí TASK ‚Üí inserta en leads_final


#### üìä Dashboard de Leads

Este proyecto incluye un panel de visualizaci√≥n frontend en React, conectado a un backend FastAPI y una base de datos en Snowflake.

##### üñ•Ô∏è Interfaz del Dashboard de Leads

El frontend de la aplicaci√≥n proporciona un dashboard interactivo con un panel lateral y m√∫ltiples secciones visuales para la gesti√≥n de leads. Est√° construido en React y se conecta al backend para visualizar, puntuar y explorar datos directamente desde Snowflake.

##### Caracter√≠sticas principales

- üìä Gr√°ficos de desempe√±o y fuentes de leads
- üìã Vista tabular de los datos cargados
- üß† Panel de scoring autom√°tico para leads


![image](https://github.com/user-attachments/assets/39bd3cc2-cd1c-4208-8bef-73be3da3d5c5)


> La imagen anterior representa la vista "Gr√°ficos", donde se muestran an√°lisis visuales sobre puntuaci√≥n, conversi√≥n y actividad de los leads.

---

#### Pr√≥ximos Pasos

- Implementar AWS Lambda y API Gateway.
- Mover l√≥gica de transformaci√≥n a Snowflake.
- Pruebas de carga y optimizaci√≥n del rendimiento.

---

## üß± Preparaci√≥n Inicial en Snowflake

### Creaci√≥n de Formato de Archivo, Stage y Tabla

```sql
CREATE OR REPLACE FILE FORMAT json_as_variant
  TYPE = 'JSON'
  COMPRESSION = 'GZIP'
  STRIP_OUTER_ARRAY = FALSE
  ENABLE_OCTAL = FALSE;

CREATE OR REPLACE STAGE leads_internal_stage
  FILE_FORMAT = json_as_variant;

CREATE OR REPLACE TABLE leads_raw (
    filename STRING,
    data VARIANT
);
```

### Consultas para Validar Objetos y Archivos en Stage

```sql
LIST @leads_internal_stage;
SELECT * FROM leads_raw;
```

### Ejemplo de Carga Manual para Validar COPY INTO

```sql
COPY INTO leads_raw(filename, data)
FROM (
    SELECT 'tmpq4lxyf6a_cleaned.json.gz' AS filename, $1
    FROM @leads_internal_stage/tmp0d0wpt2c_cleaned.json/tmp0d0wpt2c_cleaned.json.gz
)
FILE_FORMAT = (FORMAT_NAME = 'json_as_variant')
ON_ERROR = 'CONTINUE';

SELECT * FROM leads_raw;
```

### Consultas para Inspecci√≥n de Archivos JSON

```sql
SELECT $1:Prospect_ID::STRING 
FROM @leads_internal_stage/tmpq4lxyf6a_cleaned.json/tmpq4lxyf6a_cleaned.json.gz 
(FILE_FORMAT => 'json_as_variant') 
LIMIT 10;
```

### Procedimiento Almacenado para Validar y Cargar JSON

```sql
CREATE OR REPLACE PROCEDURE validate_and_load_json()
  RETURNS STRING
  LANGUAGE JAVASCRIPT
  EXECUTE AS CALLER
AS
$$
try {
    snowflake.createStatement({
        sqlText: `CREATE TEMPORARY TABLE IF NOT EXISTS temp_file_list (filename STRING, row_count NUMBER, column_count NUMBER)`
    }).execute();

    let fileList = snowflake.createStatement({
        sqlText: `SELECT DISTINCT METADATA$FILENAME AS filename FROM @leads_internal_stage LIMIT 1`
    }).execute();

    while (fileList.next()) {
        let filename = fileList.getColumnValue(1);

        try {
            let rowCount = snowflake.createStatement({
                sqlText: `SELECT COUNT(*) FROM @leads_internal_stage/${filename}`
            }).execute().getColumnValue(1);

            let columnCount = snowflake.createStatement({
                sqlText: `SELECT COUNT(*) FROM TABLE(INFER_SCHEMA(location=>'@leads_internal_stage/', pattern=>'${filename}'))`
            }).execute().getColumnValue(1);

            snowflake.createStatement({
                sqlText: `INSERT INTO temp_file_list (filename, row_count, column_count) VALUES ('${filename}', ${rowCount}, ${columnCount})`
            }).execute();

        } catch (error) {
            snowflake.createStatement({
                sqlText: `INSERT INTO temp_file_list (filename) VALUES ('${filename}')`
            }).execute();
            return `Error procesando archivo: ${filename} - ${error}`;
        }
    }

    let resultSet = snowflake.createStatement({
        sqlText: 'SELECT * FROM temp_file_list'
    }).execute();

    let result = '';
    while (resultSet.next()) {
        let filename = resultSet.getColumnValue(1);
        let rowCount = resultSet.getColumnValue(2) || 0;
        let columnCount = resultSet.getColumnValue(3) || 0;
        result += `Archivo: ${filename}, Filas: ${rowCount}, Columnas: ${columnCount}
`;
    }

    return result || 'Proceso completado sin errores';
} catch (e) {
    return `Error ejecutando el procedimiento: ${e}`;
}
$$;
```

### Consultas para Inspecci√≥n y Carga Espec√≠fica

```sql
SELECT 'tmpmcu1c5l6_cleaned.json.gz' AS filename, $1
FROM @leads_internal_stage/tmpmcu1c5l6_cleaned.json.gz;

SELECT 
    filename,
    data:"Prospect_ID"::STRING AS prospect_id
FROM leads_raw
LIMIT 10;

SELECT $1:"prospect_id" AS prospect_id
FROM @leads_internal_stage/tmprqsaeu0j_cleaned.json/tmprqsaeu0j_cleaned.json.gz
(FILE_FORMAT => json_as_variant)
LIMIT 5;
```

---

## üõ†Ô∏è Configuraci√≥n del Entorno

Este proyecto requiere un archivo `.env` con variables de entorno espec√≠ficas para conectarse a servicios como AWS (LocalStack) y Snowflake.

---

## üìå Prerrequisitos

Crea un archivo `.env` dentro de la carpeta `env/` con el siguiente contenido:

```env
# Archivo: env/.env

# Configuraci√≥n de AWS y LocalStack
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
S3_ENDPOINT_URL=http://localstack:4566
S3_BUCKET=leads-bucket

# Credenciales de Snowflake
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_ACCOUNT=your_account_id
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=LEADS_DB
SNOWFLAKE_SCHEMA=PUBLIC
SNOWFLAKE_ROLE=SYSADMIN
```

## Componentes necesarios en Snowflake

| Componente         | Detalle                                       |
| ------------------ | --------------------------------------------- |
| Tabla en Snowflake | `leads_raw(filename STRING, data VARIANT)`    |
| Stage              | Apunta a bucket `leads-bucket` en LocalStack  |
| Snowpipe           | Carga desde `@mystage` usando `PARSE_JSON`    |
| FastAPI            | Subir a S3 y luego `REFRESH PIPE` manual      |
| Consulta           | Lee desde Snowflake y descompone el `VARIANT` |

---

## üöÄ Despliegue con Docker

Sigue estos pasos para levantar los servicios con Docker y cargar las variables de entorno desde el archivo `.env`:

1. Abre una terminal en la ra√≠z del proyecto.
2. Ejecuta el siguiente comando:

```bash
docker-compose --env-file env/.env up --build
```

Esto levantar√° los contenedores usando las variables definidas en `env/.env`.

---

## üõ† Configuraci√≥n del Frontend en Codespaces

Si est√°s usando Codespaces para el frontend, sigue estos pasos para asegurarte de que Node.js y npm est√©n correctamente configurados:

### **1. Verificar si Node.js est√° Instalado**

Primero, verifica si Node.js est√° instalado:

```bash
node -v
npm -v
```

Si esto no devuelve un n√∫mero de versi√≥n, significa que Node.js y npm no est√°n instalados.

---

### **2. Instalar Node.js en Codespace**

Si no est√°n instalados, puedes usar nvm (Node Version Manager) para instalar Node.js:

```bash
# Instalar nvm (si no est√° instalado)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash

# Cargar nvm en el terminal actual
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"

# Verificar que nvm se instal√≥ correctamente
nvm --version
```

Ahora instala Node.js usando nvm:

```bash
# Instalar la √∫ltima versi√≥n LTS de Node.js
nvm install --lts

# Usar esta versi√≥n por defecto
nvm use --lts

# Verificar que Node.js y npm est√°n instalados correctamente
node -v
npm -v
```

---

### **3. Instalar las Dependencias del Frontend**

Ahora puedes ir a la carpeta `frontend` y ejecutar:

```bash
cd frontend
npm install
```

---

### **4. Crear un Archivo `.nvmrc` (Opcional pero Recomendado)**

Para asegurarte de que siempre se use la misma versi√≥n de Node.js en tu proyecto, puedes crear un archivo `.nvmrc` en la ra√≠z de tu proyecto con el siguiente contenido:

```
lts/*
```

---

### **5. Verificar el PATH (Si Todav√≠a Hay Problemas)**

Si sigues teniendo problemas, aseg√∫rate de que el PATH de nvm est√© correctamente configurado. Puedes agregar esto a tu archivo `~/.bashrc`, `~/.zshrc` o `~/.bash_profile`:

```bash
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
```

Luego, recarga el perfil:

```bash
source ~/.bashrc  # o ~/.zshrc o ~/.bash_profile, dependiendo de tu shell
```


## ‚úÖ Verificaci√≥n de variables de entorno

1. Obt√©n el nombre del contenedor en ejecuci√≥n:

```bash
docker ps
```

2. Accede al contenedor e imprime las variables de entorno:

```bash
docker exec -it <nombre_del_contenedor> env
```

3. Revisar los logs del contenedor:

```bash
docker logs <nombre_del_contenedor>
```

---


## üß™ Comprobaci√≥n r√°pida (opcional)

Puedes probar que la variable del bucket de S3 se carga correctamente ejecutando un comando dentro del contenedor (ejemplo):

```bash
echo $S3_BUCKET
```
Probar que aplicacion de fast api se ejecuta correctamente 
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
Probar subida de archivo a trav√©s del endpoint /upload-and-load/ en FastAPI:
```bash
curl -X 'POST' 'http://0.0.0.0:8000/upload-and-load/' -F 'file=@/workspaces/lead-scoring-pipeline/data/SampleData.csv'

```
---

## üìÖ D√≠a 1: Preparaci√≥n y Dise√±o del Sistema

### 1.1 An√°lisis del Proyecto y Requisitos

Tareas:

* Identificar los tipos de datos que necesitas procesar (leads, fuentes, puntuaci√≥n).
* Definir las herramientas y tecnolog√≠as necesarias: Snowflake, AWS LocalStack, Python, ML Model, etc.

### 1.2 Definir la Arquitectura de la Soluci√≥n

Arquitectura Propuesta:

* **Entrada de Datos (AWS LocalStack + S3)**: Los leads ser√°n almacenados en archivos en S3 (simulado con LocalStack en tu entorno local). Los datos de cada lead estar√°n en formato JSON.
* **Procesamiento de Datos ( Snowflake UDF)**: Utilizar  una UDF en Snowflake para procesar cada lead.
* **Modelo de Scoring (ML)**: Crear un modelo b√°sico de scoring usando Python o reglas simples.
* **Almacenamiento de Resultados (Snowflake)**: Los resultados del scoring se almacenar√°n en una tabla de Snowflake.
* **Interfaz de Consulta**: Una consulta SQL que permita al cliente revisar los resultados de los leads puntuados.

---

## üìÖ D√≠a 1: Desarrollo de la Funcionalidad B√°sica

### 2.1 Configuraci√≥n del Entorno Local (AWS LocalStack + Snowflake)

Tareas:
* Configurar LocalStack para emular servicios de AWS S3 y Lambda.

* Configurar Snowflake 

* Configurar AWS SDK (Boto3) y librer√≠as necesarias para interactuar con LocalStack y Snowflake.

* Crear un contenedor Docker para FastAPI que se conecte a LocalStack y Snowflake.

### 2.2 Desarrollo del Modelo de Scoring

* Desarrollar un modelo simple para calificar leads.
* Implementar reglas de negocio b√°sicas para puntuar cada lead en funci√≥n de su origen o caracter√≠sticas.

### 2.3 Implementaci√≥n de la Funci√≥n de Scoring (UDF)

* **Snowflake UDF**:

  *  UDF (funci√≥n definida por el usuario) en Python que reciba los datos del lead (en formato JSON) y calcule la puntuaci√≥n.

### 2.4 Cargar los Datos de Leads en AWS S3 (Simulado con LocalStack)

* Carga de  archivos de ejemplo de leads en S3 para simular el proceso. Cada archivo contendr√° un JSON con los datos del lead.
* 
### 2.5 Servir Datos desde Snowflake a FastAPI

* Configurar FastAPI para conectarse a Snowflake y exponer endpoints para consultar los leads puntuados.
---

## üìÖ D√≠a 1: Ingesta y Procesamiento de Datos en Snowflake

### 3.1 Configuraci√≥n de Snowpipe para Automatizaci√≥n

Pasos para configurar Snowpipe:

* Crear un **stage externo** en Snowflake apuntando al bucket de S3.
* Configurar **Snowpipe** para mover los datos autom√°ticamente desde S3 a Snowflake.

### 3.2 Almacenamiento de Resultados en Snowflake

Crea una tabla en Snowflake para almacenar los resultados del scoring de los leads:

```sql
CREATE OR REPLACE TABLE leads (
    lead_id STRING,
    lead_name STRING,
    lead_source STRING,
    score FLOAT
);
```

### 3.3 Crear el Pipe para Snowpipe

```sql
CREATE OR REPLACE PIPE my_lead_pipe
  AUTO_INGEST = TRUE
  AS
  COPY INTO leads
  FROM @my_s3_stage
  FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"')
  ON_ERROR = 'CONTINUE';
```

* **AUTO\_INGEST = TRUE**: Hace que Snowpipe ingiera autom√°ticamente los archivos tan pronto como se carguen en el bucket de S3.
* **COPY INTO leads**: Especifica que los datos deben ser cargados en la tabla leads.

### 3.4 Configurar Notificaciones en S3

* Configurar un evento de notificaci√≥n en S3 para activar Snowpipe cuando se suban nuevos archivos al bucket.

### 3.5 Verificaci√≥n y Pruebas

```sql
SELECT * FROM SNOWPIPE_LOAD_HISTORY WHERE PIPE_NAME = 'my_lead_pipe';
```

Verifica que los datos se est√°n cargando correctamente.

---

## üìÖ D√≠a 4: Aplicaci√≥n de Reglas de Scoring en Snowflake

### 4.1 Crear Procedimientos Almacenados para Scoring

```sql
CREATE OR REPLACE PROCEDURE apply_scoring()
RETURNS STRING
LANGUAGE SQL
AS
$$
BEGIN
    UPDATE leads
    SET score = CASE
        WHEN lead_source = 'Marketing' THEN 1
        ELSE 0
    END
    WHERE score IS NULL;
    RETURN 'Scoring applied successfully!';
END;
$$;
```

### 4.2 Crear Tarea Programada para Automatizaci√≥n

```sql
CREATE OR REPLACE TASK apply_scoring_task
WAREHOUSE = my_warehouse
SCHEDULE = 'USING CRON 0 * * * * UTC'
AS
CALL apply_scoring();
```

---

## ‚úÖ Mejoras

* Integrar monitoreo y alertas para Snowpipe.
* Mejorar las reglas de scoring.
* Crear interfaz para visualizar los resultados.
* Automatizar despliegue con AWS SAM o Terraform.

# üöÄ Sprint 2: Arquitectura Serverless e Integraci√≥n en AWS

Como parte de la evoluci√≥n del proyecto, se implement√≥ una arquitectura serverless completa en AWS, integrando Snowflake, Lambda, API Gateway, S3, CloudFront y otros servicios clave.

---

### ‚úÖ Mejoras en el Backend (FastAPI + AWS Lambda)

- Se adapt√≥ el backend construido con **FastAPI** para ejecutarse en **AWS Lambda** mediante contenedores (Docker) y `Mangum`.
- Se estructur√≥ la carga segura de variables con un archivo `.env` dentro de `app/env/.env`.
- Se refactoriz√≥ el `Dockerfile` para incluir solo dependencias necesarias y reducir el peso de la imagen.
- Se conect√≥ correctamente Lambda a Snowflake para operaciones SQL, `PUT` y Snowpipe.
- Se expusieron endpoints como `/leads`, `/upload`, `/score-lead` y `/lead-count` a trav√©s de **API Gateway**.

---

### üåê Mejora del Frontend (S3 + CloudFront)

- Se despleg√≥ el frontend como sitio est√°tico en **Amazon S3**.
- Se cre√≥ una distribuci√≥n de **CloudFront** para servir el sitio globalmente con mejor performance.
- Se habilit√≥ **CORS** en el backend para aceptar peticiones desde CloudFront y otros or√≠genes permitidos.

---

### ‚öôÔ∏è Despliegue con AWS CLI

#### üîπ Crear repositorio en ECR:
```bash
aws ecr create-repository --repository-name lead-scoring-api --region eu-west-1
```

#### üîπ Login e imagen Docker:
```bash
aws ecr get-login-password --region eu-west-1 | docker login --username AWS --password-stdin 109169735576.dkr.ecr.eu-west-1.amazonaws.com
docker build -t lead-scoring-api .
docker tag lead-scoring-api:latest 109169735576.dkr.ecr.eu-west-1.amazonaws.com/lead-scoring-api:latest
docker push 109169735576.dkr.ecr.eu-west-1.amazonaws.com/lead-scoring-api:latest
```

#### üîπ Crear funci√≥n Lambda desde imagen:
```bash
aws lambda create-function --function-name lead-scoring-api \
  --package-type Image \
  --code ImageUri=109169735576.dkr.ecr.eu-west-1.amazonaws.com/lead-scoring-api:latest \
  --role arn:aws:iam::109169735576:role/lambda-execution-role \
  --region eu-west-1 --timeout 60 --memory-size 1024
```

#### üîπ API Gateway conectado a Lambda:
```bash
aws apigatewayv2 create-api \
  --name lead-scoring-api \
  --protocol-type HTTP \
  --target arn:aws:lambda:eu-west-1:109169735576:function:lead-scoring-api
```

#### üîπ Hosting frontend en S3 + CloudFront:
```bash
aws s3api create-bucket --bucket lead-scoring-frontend --region eu-west-1
aws s3 website s3://lead-scoring-frontend/ --index-document index.html
aws s3 sync ./frontend/dist/ s3://lead-scoring-frontend/
aws cloudfront create-distribution --origin-domain-name lead-scoring-frontend.s3-website-eu-west-1.amazonaws.com
```
Obtener id de distribucion de Cloudfront
```bash
aws cloudfront list-distributions \
  --query "DistributionList.Items[*].{Id:Id,DomainName:DomainName}" \
  --output table
```
---


#### üîπPayload de prueba para AWS Lambda:

```bash
 {
  "version": "2.0",
  "routeKey": "GET /leads/",
  "rawPath": "/leads/",
  "rawQueryString": "",
  "headers": {
    "host": "localhost",
    "user-agent": "aws-cli/2.0",
    "x-forwarded-for": "127.0.0.1"
  },
  "requestContext": {
    "http": {
      "method": "GET",
      "path": "/leads/",
      "protocol": "HTTP/1.1",
      "sourceIp": "127.0.0.1",
      "userAgent": "aws-cli/2.0"
    }
  },
  "isBase64Encoded": false
} 
```

### Habilitar onfiguraci√≥n de sitio web est√°tico en bucket
```bash 
aws s3 website s3://lead-scoring-frontend/ --index-document index.html --error-document index.html
```
---

### üîì Permitir acceso p√∫blico al frontend en S3

Para que CloudFront (o cualquier navegador) pueda servir tu frontend almacenado en S3, debes asegurarte de que los archivos sean p√∫blicamente accesibles. Esto se logra aplicando una pol√≠tica de bucket que permita lecturas an√≥nimas.

#### üõ†Ô∏è Comando para aplicar pol√≠tica p√∫blica al bucket

```bash
aws s3api put-bucket-policy --bucket lead-scoring-frontend --policy file://<(cat <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::lead-scoring-frontend/*"
    }
  ]
}
EOF
)
```

## üöÄ Despliegue de Frontend (Lead Scoring)

Cada vez que se modifica el c√≥digo del frontend, ejecutar los siguientes comandos para actualizar el entorno en producci√≥n (S3 + CloudFront):

```bash
# 1. Generar la build del frontend
npm run build

# 2. Subir la carpeta 'build/' al bucket de S3
aws s3 sync ./build/ s3://lead-scoring-frontend --delete

# 3. (Solo si es necesario) Configurar el bucket como sitio web est√°tico
aws s3 website s3://lead-scoring-frontend/ --index-document index.html

# 4. Invalidar cach√© de CloudFront para aplicar cambios
aws cloudfront create-invalidation \
  --distribution-id <ID_DE_TU_DISTRIBUCION> \
  --paths "/*"
```
### üß† Servicios y funcionalidades integradas

- **Snowflake**: Carga de datos, funciones de scoring, tareas programadas.
- **AWS Lambda**: Backend sin servidores.
- **API Gateway**: Exposici√≥n de endpoints p√∫blicos.
- **Amazon S3 + CloudFront**: Hosting global del frontend.
- **AWS SageMaker**: Scoring predictivo de leads.
- **AWS Athena**: Conteo de registros desde datos crudos en S3.
- **AWS CloudWatch**: Monitoreo de logs.
- **PowerCurve (futuro)**: Considerado para administraci√≥n avanzada de usuarios.

