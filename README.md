 Lead Scoring Pipeline

## üìã Objetivo del Proyecto

Crear una soluci√≥n que reciba datos de leads, realice una puntuaci√≥n (**scoring**) utilizando un modelo simple y almacene los resultados de manera estructurada en Snowflake. Esto incluye la ingesta de datos desde S3 (, el procesamiento del scoring y la automatizaci√≥n de la carga de datos.

---

## üìà Iterative Development ‚Äì Sprints Overview (üìÖ Agile Sprint Plan). 2 D√≠as

### Sprint 1 - Procesamiento de Leads

#### Funcionalidades Implementadas

1. **Carga de Archivos CSV y JSON**
   - Procesamiento de archivos CSV para convertirlos a formato JSON.
   - Manejo de valores nulos y limpieza de datos para asegurar la integridad.
   - Generaci√≥n de archivos JSON y carga a Snowflake mediante stages internos.

2. **Optimizaci√≥n del Pipeline**
   - Ajustes en el formato de archivos para evitar problemas de formato (.json.gz).
   - Implementaci√≥n de scripts para manejar errores de datos y compatibilidad.

3. **Validaci√≥n de Archivos en Snowflake**
   - Procedimientos almacenados para validar la estructura de archivos antes de cargar.
   - Scripts para verificar la existencia de columnas y filas antes de insertar datos.
   - Pruebas en IU de Snowflake.

#### Consideraciones T√©cnicas para la Carga y Procesamiento de Datos

1. **Separaci√≥n de Tablas**
   - leads_raw: tabla intermedia que almacena los datos en formato JSON crudo.
   - leads_final: tabla destino con los datos desplegados en columnas estructuradas.

2. **Carga Incremental**
   - Comparaci√≥n por identificadores √∫nicos como Prospect_ID.
   - Uso de campos de fecha de actualizaci√≥n o generaci√≥n de hash/checksum.

3. **Automatizaci√≥n del Flujo**
   - **Procedimientos Almacenados (PA):** l√≥gica de validaci√≥n de ficheros y creacion de tabla a partir de estructura de fichero JSON cargado en internal stage
   - **TASK:** Carga datos en tabla leads_final.
   - **STREAMs:** detectan nuevos registros en tabla leads_raw y activa task de carga en tabla final.
   - **Snowpipe:** automatiza la ingesta continua.

> Estas consideraciones permitir√°n escalar el pipeline de forma robusta, controlada y optimizada para entornos de producci√≥n.

#### Problemas Encontrados

- **Errores de Compresi√≥n y Formato**
  - Archivos subidos como .json.gz causaban errores.
  - Configuraci√≥n corregida para evitar errores de conteo de filas y columnas.
  - Snowflake renombraba autom√°ticamente los archivos, dificultando su carga con COPY INTO.

- **Errores en Procedimientos Almacenados**
  - Ajustes de sintaxis y l√≥gica en procedimientos.
  - Mejor manejo de excepciones y mensajes de error.

- **Configuraci√≥n de FastAPI**
  - Archivos mal subidos por configuraciones incorrectas.
  - Ajuste de rutas para evitar subcarpetas en stages.

#### Soluciones Aplicadas

- Validaci√≥n desde Snowflake SQL worksheet.
- Conversi√≥n de JSON a NDJSON.
- Eliminaci√≥n de compresi√≥n innecesaria.
- Captura del nombre renombrado con UUID tras el comando PUT.
- Ruta correcta en PUT y COPY INTO. Finalmente, se opta por el siguiente flujo de datos : Snowpipe carga en leads_raw  datos de JSON‚Üí (detected by STREAM) ‚Üí TASK ‚Üí inserta en leads_finalleads_raw ‚Üí (detected by STREAM) ‚Üí TASK ‚Üí inserta en leads_final


#### üìä Dashboard de Leads

Este proyecto incluye un panel de visualizaci√≥n frontend en React, conectado a un backend FastAPI y una base de datos en Snowflake.

##### üñ•Ô∏è Interfaz del Dashboard de Leads

El frontend de la aplicaci√≥n proporciona un dashboard interactivo con un panel lateral y m√∫ltiples secciones visuales para la gesti√≥n de leads. Est√° construido en React y se conecta al backend para visualizar, puntuar y explorar datos directamente desde Snowflake.

##### Caracter√≠sticas principales

- üìä Gr√°ficos de desempe√±o y fuentes de leads
- üìã Vista tabular de los datos cargados
- üß† Panel de scoring autom√°tico para leads


![image](https://github.com/user-attachments/assets/39bd3cc2-cd1c-4208-8bef-73be3da3d5c5)


> La imagen anterior representa la vista "Gr√°ficos", donde se muestran an√°lisis visuales sobre puntuaci√≥n, conversi√≥n y actividad de los leads.

---

#### Pr√≥ximos Pasos

- Implementar AWS Lambda y API Gateway.
- Mover l√≥gica de transformaci√≥n a Snowflake.
- Pruebas de carga y optimizaci√≥n del rendimiento.

---

## üß± Preparaci√≥n Inicial en Snowflake

### Creaci√≥n de Formato de Archivo, Stage y Tabla

```sql
CREATE OR REPLACE FILE FORMAT json_as_variant
  TYPE = 'JSON'
  COMPRESSION = 'GZIP'
  STRIP_OUTER_ARRAY = FALSE
  ENABLE_OCTAL = FALSE;

CREATE OR REPLACE STAGE leads_internal_stage
  FILE_FORMAT = json_as_variant;

CREATE OR REPLACE TABLE leads_raw (
    filename STRING,
    data VARIANT
);
```

### Consultas para Validar Objetos y Archivos en Stage

```sql
LIST @leads_internal_stage;
SELECT * FROM leads_raw;
```

### Ejemplo de Carga Manual para Validar COPY INTO

```sql
COPY INTO leads_raw(filename, data)
FROM (
    SELECT 'tmpq4lxyf6a_cleaned.json.gz' AS filename, $1
    FROM @leads_internal_stage/tmp0d0wpt2c_cleaned.json/tmp0d0wpt2c_cleaned.json.gz
)
FILE_FORMAT = (FORMAT_NAME = 'json_as_variant')
ON_ERROR = 'CONTINUE';

SELECT * FROM leads_raw;
```

### Consultas para Inspecci√≥n de Archivos JSON

```sql
SELECT $1:Prospect_ID::STRING 
FROM @leads_internal_stage/tmpq4lxyf6a_cleaned.json/tmpq4lxyf6a_cleaned.json.gz 
(FILE_FORMAT => 'json_as_variant') 
LIMIT 10;
```

### Procedimiento Almacenado para Validar y Cargar JSON

```sql
CREATE OR REPLACE PROCEDURE validate_and_load_json()
  RETURNS STRING
  LANGUAGE JAVASCRIPT
  EXECUTE AS CALLER
AS
$$
try {
    snowflake.createStatement({
        sqlText: `CREATE TEMPORARY TABLE IF NOT EXISTS temp_file_list (filename STRING, row_count NUMBER, column_count NUMBER)`
    }).execute();

    let fileList = snowflake.createStatement({
        sqlText: `SELECT DISTINCT METADATA$FILENAME AS filename FROM @leads_internal_stage LIMIT 1`
    }).execute();

    while (fileList.next()) {
        let filename = fileList.getColumnValue(1);

        try {
            let rowCount = snowflake.createStatement({
                sqlText: `SELECT COUNT(*) FROM @leads_internal_stage/${filename}`
            }).execute().getColumnValue(1);

            let columnCount = snowflake.createStatement({
                sqlText: `SELECT COUNT(*) FROM TABLE(INFER_SCHEMA(location=>'@leads_internal_stage/', pattern=>'${filename}'))`
            }).execute().getColumnValue(1);

            snowflake.createStatement({
                sqlText: `INSERT INTO temp_file_list (filename, row_count, column_count) VALUES ('${filename}', ${rowCount}, ${columnCount})`
            }).execute();

        } catch (error) {
            snowflake.createStatement({
                sqlText: `INSERT INTO temp_file_list (filename) VALUES ('${filename}')`
            }).execute();
            return `Error procesando archivo: ${filename} - ${error}`;
        }
    }

    let resultSet = snowflake.createStatement({
        sqlText: 'SELECT * FROM temp_file_list'
    }).execute();

    let result = '';
    while (resultSet.next()) {
        let filename = resultSet.getColumnValue(1);
        let rowCount = resultSet.getColumnValue(2) || 0;
        let columnCount = resultSet.getColumnValue(3) || 0;
        result += `Archivo: ${filename}, Filas: ${rowCount}, Columnas: ${columnCount}
`;
    }

    return result || 'Proceso completado sin errores';
} catch (e) {
    return `Error ejecutando el procedimiento: ${e}`;
}
$$;
```

### Consultas para Inspecci√≥n y Carga Espec√≠fica

```sql
SELECT 'tmpmcu1c5l6_cleaned.json.gz' AS filename, $1
FROM @leads_internal_stage/tmpmcu1c5l6_cleaned.json.gz;

SELECT 
    filename,
    data:"Prospect_ID"::STRING AS prospect_id
FROM leads_raw
LIMIT 10;

SELECT $1:"prospect_id" AS prospect_id
FROM @leads_internal_stage/tmprqsaeu0j_cleaned.json/tmprqsaeu0j_cleaned.json.gz
(FILE_FORMAT => json_as_variant)
LIMIT 5;
```

---

## üõ†Ô∏è Configuraci√≥n del Entorno

Este proyecto requiere un archivo `.env` con variables de entorno espec√≠ficas para conectarse a servicios como AWS (LocalStack) y Snowflake.

---

## üìå Prerrequisitos

Crea un archivo `.env` dentro de la carpeta `env/` con el siguiente contenido:

```env
# Archivo: env/.env

# Configuraci√≥n de AWS y LocalStack
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
S3_ENDPOINT_URL=http://localstack:4566
S3_BUCKET=your-bucket-name

# Credenciales de Snowflake
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_ACCOUNT=your_account_id
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=LEADS_DB
SNOWFLAKE_SCHEMA=PUBLIC
SNOWFLAKE_ROLE=SYSADMIN
```

## Componentes necesarios en Snowflake

| Componente         | Detalle                                       |
| ------------------ | --------------------------------------------- |
| Tabla en Snowflake | `leads_raw(filename STRING, data VARIANT)`    |
| Stage              | Apunta a bucket `your-bucket-name` en LocalStack  |
| Snowpipe           | Carga desde `@mystage` usando `PARSE_JSON`    |
| FastAPI            | Subir a S3 y luego `REFRESH PIPE` manual      |
| Consulta           | Lee desde Snowflake y descompone el `VARIANT` |

---

## üöÄ Despliegue con Docker

Sigue estos pasos para levantar los servicios con Docker y cargar las variables de entorno desde el archivo `.env`:

1. Abre una terminal en la ra√≠z del proyecto.
2. Ejecuta el siguiente comando:

```bash
docker-compose --env-file env/.env up --build
```

Esto levantar√° los contenedores usando las variables definidas en `env/.env`.

---

## üõ† Configuraci√≥n del Frontend en Codespaces

Si est√°s usando Codespaces para el frontend, sigue estos pasos para asegurarte de que Node.js y npm est√©n correctamente configurados:

### **1. Verificar si Node.js est√° Instalado**

Primero, verifica si Node.js est√° instalado:

```bash
node -v
npm -v
```

Si esto no devuelve un n√∫mero de versi√≥n, significa que Node.js y npm no est√°n instalados.

---

### **2. Instalar Node.js en Codespace**

Si no est√°n instalados, puedes usar nvm (Node Version Manager) para instalar Node.js:

```bash
# Instalar nvm (si no est√° instalado)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash

# Cargar nvm en el terminal actual
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"

# Verificar que nvm se instal√≥ correctamente
nvm --version
```

Ahora instala Node.js usando nvm:

```bash
# Instalar la √∫ltima versi√≥n LTS de Node.js
nvm install --lts

# Usar esta versi√≥n por defecto
nvm use --lts

# Verificar que Node.js y npm est√°n instalados correctamente
node -v
npm -v
```

---

### **3. Instalar las Dependencias del Frontend**

Ahora puedes ir a la carpeta `frontend` y ejecutar:

```bash
cd frontend
npm install
```

---

### **4. Crear un Archivo `.nvmrc` (Opcional pero Recomendado)**

Para asegurarte de que siempre se use la misma versi√≥n de Node.js en tu proyecto, puedes crear un archivo `.nvmrc` en la ra√≠z de tu proyecto con el siguiente contenido:

```
lts/*
```

---

### **5. Verificar el PATH (Si Todav√≠a Hay Problemas)**

Si sigues teniendo problemas, aseg√∫rate de que el PATH de nvm est√© correctamente configurado. Puedes agregar esto a tu archivo `~/.bashrc`, `~/.zshrc` o `~/.bash_profile`:

```bash
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
```

Luego, recarga el perfil:

```bash
source ~/.bashrc  # o ~/.zshrc o ~/.bash_profile, dependiendo de tu shell
```


## ‚úÖ Verificaci√≥n de variables de entorno

1. Obt√©n el nombre del contenedor en ejecuci√≥n:

```bash
docker ps
```

2. Accede al contenedor e imprime las variables de entorno:

```bash
docker exec -it <nombre_del_contenedor> env
```

3. Revisar los logs del contenedor:

```bash
docker logs <nombre_del_contenedor>
```

---


## üß™ Comprobaci√≥n r√°pida (opcional)

Puedes probar que la variable del bucket de S3 se carga correctamente ejecutando un comando dentro del contenedor (ejemplo):

```bash
echo $S3_BUCKET
```
Probar que aplicacion de fast api se ejecuta correctamente 
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
Probar subida de archivo a trav√©s del endpoint /upload-and-load/ en FastAPI:
```bash
curl -X 'POST' 'http://0.0.0.0:8000/upload-and-load/' -F 'file=@/workspaces/lead-scoring-pipeline/data/SampleData.csv'

```
---

## üìÖ D√≠a 1: Preparaci√≥n y Dise√±o del Sistema

### 1.1 An√°lisis del Proyecto y Requisitos

Tareas:

* Identificar los tipos de datos que necesitas procesar (leads, fuentes, puntuaci√≥n).
* Definir las herramientas y tecnolog√≠as necesarias: Snowflake, AWS LocalStack, Python, ML Model, etc.

### 1.2 Definir la Arquitectura de la Soluci√≥n

Arquitectura Propuesta:

* **Entrada de Datos (AWS LocalStack + S3)**: Los leads ser√°n almacenados en archivos en S3 (simulado con LocalStack en tu entorno local). Los datos de cada lead estar√°n en formato JSON.
* **Procesamiento de Datos ( Snowflake UDF)**: Utilizar  una UDF en Snowflake para procesar cada lead.
* **Modelo de Scoring (ML)**: Crear un modelo b√°sico de scoring usando Python o reglas simples.
* **Almacenamiento de Resultados (Snowflake)**: Los resultados del scoring se almacenar√°n en una tabla de Snowflake.
* **Interfaz de Consulta**: Una consulta SQL que permita al cliente revisar los resultados de los leads puntuados.

---

## üìÖ D√≠a 1: Desarrollo de la Funcionalidad B√°sica

### 2.1 Configuraci√≥n del Entorno Local (AWS LocalStack + Snowflake)

Tareas:
* Configurar LocalStack para emular servicios de AWS S3 y Lambda.

* Configurar Snowflake 

* Configurar AWS SDK (Boto3) y librer√≠as necesarias para interactuar con LocalStack y Snowflake.

* Crear un contenedor Docker para FastAPI que se conecte a LocalStack y Snowflake.

### 2.2 Desarrollo del Modelo de Scoring

* Desarrollar un modelo simple para calificar leads.
* Implementar reglas de negocio b√°sicas para puntuar cada lead en funci√≥n de su origen o caracter√≠sticas.

### 2.3 Implementaci√≥n de la Funci√≥n de Scoring (UDF)

* **Snowflake UDF**:

  *  UDF (funci√≥n definida por el usuario) en Python que reciba los datos del lead (en formato JSON) y calcule la puntuaci√≥n.

### 2.4 Cargar los Datos de Leads en AWS S3 (Simulado con LocalStack)

* Carga de  archivos de ejemplo de leads en S3 para simular el proceso. Cada archivo contendr√° un JSON con los datos del lead.
* 
### 2.5 Servir Datos desde Snowflake a FastAPI

* Configurar FastAPI para conectarse a Snowflake y exponer endpoints para consultar los leads puntuados.
---

## üìÖ D√≠a 1: Ingesta y Procesamiento de Datos en Snowflake

### 3.1 Configuraci√≥n de Snowpipe para Automatizaci√≥n

Pasos para configurar Snowpipe:

* Crear un **stage externo** en Snowflake apuntando al bucket de S3.
* Configurar **Snowpipe** para mover los datos autom√°ticamente desde S3 a Snowflake.

### 3.2 Almacenamiento de Resultados en Snowflake

Crea una tabla en Snowflake para almacenar los resultados del scoring de los leads:

```sql
CREATE OR REPLACE TABLE leads (
    lead_id STRING,
    lead_name STRING,
    lead_source STRING,
    score FLOAT
);
```

### 3.3 Crear el Pipe para Snowpipe

```sql
CREATE OR REPLACE PIPE my_lead_pipe
  AUTO_INGEST = TRUE
  AS
  COPY INTO leads
  FROM @my_s3_stage
  FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"')
  ON_ERROR = 'CONTINUE';
```

* **AUTO\_INGEST = TRUE**: Hace que Snowpipe ingiera autom√°ticamente los archivos tan pronto como se carguen en el bucket de S3.
* **COPY INTO leads**: Especifica que los datos deben ser cargados en la tabla leads.

### 3.4 Configurar Notificaciones en S3

* Configurar un evento de notificaci√≥n en S3 para activar Snowpipe cuando se suban nuevos archivos al bucket.

### 3.5 Verificaci√≥n y Pruebas

```sql
SELECT * FROM SNOWPIPE_LOAD_HISTORY WHERE PIPE_NAME = 'my_lead_pipe';
```

Verifica que los datos se est√°n cargando correctamente.

---

## üìÖ D√≠a 4: Aplicaci√≥n de Reglas de Scoring en Snowflake

### 4.1 Crear Procedimientos Almacenados para Scoring

```sql
CREATE OR REPLACE PROCEDURE apply_scoring()
RETURNS STRING
LANGUAGE SQL
AS
$$
BEGIN
    UPDATE leads
    SET score = CASE
        WHEN lead_source = 'Marketing' THEN 1
        ELSE 0
    END
    WHERE score IS NULL;
    RETURN 'Scoring applied successfully!';
END;
$$;
```

### 4.2 Crear Tarea Programada para Automatizaci√≥n

```sql
CREATE OR REPLACE TASK apply_scoring_task
WAREHOUSE = my_warehouse
SCHEDULE = 'USING CRON 0 * * * * UTC'
AS
CALL apply_scoring();
```

---

## ‚úÖ Mejoras

* Integrar monitoreo y alertas para Snowpipe.
* Mejorar las reglas de scoring.
* Crear interfaz para visualizar los resultados.
* Automatizar despliegue con AWS SAM o Terraform.

# üöÄ Sprint 2: Arquitectura Serverless e Integraci√≥n en AWS

Como parte de la evoluci√≥n del proyecto, se implement√≥ una arquitectura serverless completa en AWS, integrando Snowflake, Lambda, API Gateway, S3, CloudFront y otros servicios clave.

---

### ‚úÖ Mejoras en el Backend (FastAPI + AWS Lambda)

- Se adapt√≥ el backend construido con **FastAPI** para ejecutarse en **AWS Lambda** mediante contenedores (Docker) y `Mangum`.
- Se estructur√≥ la carga segura de variables con un archivo `.env` dentro de `app/env/.env`.
- Se refactoriz√≥ el `Dockerfile` para incluir solo dependencias necesarias y reducir el peso de la imagen.
- Se conect√≥ correctamente Lambda a Snowflake para operaciones SQL, `PUT` y Snowpipe.
- Se expusieron endpoints como `/leads`, `/upload`, `/score-lead` y `/lead-count` a trav√©s de **API Gateway**.

---

### üåê Mejora del Frontend (S3 + CloudFront)

- Se despleg√≥ el frontend como sitio est√°tico en **Amazon S3**.
- Se cre√≥ una distribuci√≥n de **CloudFront** para servir el sitio globalmente con mejor performance.
- Se habilit√≥ **CORS** en el backend para aceptar peticiones desde CloudFront y otros or√≠genes permitidos.

---

### üß© Diagn√≥stico del Problema

#### ‚ùå Problema Inicial:
Al invocar una funci√≥n Lambda construida como imagen Docker (basada en `public.ecr.aws/lambda/python:3.11`) que contiene una aplicaci√≥n FastAPI adaptada con Mangum:

- Todas las peticiones (como `GET /`) devolv√≠an **404 Not Found** al probar localmente v√≠a Docker.
- Sin embargo, ejecutando la misma app con `uvicorn` funcionaba correctamente.
- Para evitar consumir la capa gratuita de AWS Lambda, se decidi√≥ probar localmente con **SAM**.

---

### ‚úÖ Causa Ra√≠z

Las im√°genes contenedor de Lambda **no ejecutan un servidor web** como `uvicorn`. En su lugar, esperan una **funci√≥n handler** con el formato `modulo.funci√≥n`, la cual es invocada por API Gateway u otros eventos Lambda.

Por eso, aunque tu FastAPI funcionaba bien con `uvicorn`, no respond√≠a cuando era invocada por Lambda sin el adaptador adecuado.

---

### üîß Pasos de Soluci√≥n

#### 1. ‚úÖ Estructura correcta en `main.py` con Mangum

 Lambda no entiende directamente las aplicaciones ASGI como FastAPI. Para adaptarlas, se usa **Mangum**, un adaptador que convierte los eventos de Lambda en peticiones compatibles con FastAPI.

```python
from fastapi import FastAPI
from mangum import Mangum

app = FastAPI()

@app.get("/")
def root():
    return {"message": "Hello from Lambda"}

handler = Mangum(app)
```

Esto asegura que la funci√≥n `handler` pueda ser invocada correctamente por Lambda.

---

#### 2. ‚úÖ Dockerfile

 Lambda espera que el c√≥digo est√© en `/var/task` y que la imagen defina un `CMD` que apunte al handler. Tambi√©n es necesario instalar las dependencias del sistema y de Python en la imagen.

```dockerfile
FROM public.ecr.aws/lambda/python:3.11

RUN yum install -y gcc gcc-c++ make libffi-devel python3-devel

WORKDIR /var/task

COPY requirements.txt .
RUN python3 -m pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt

COPY app/ app/

CMD ["app.main.handler"]
```

Esto asegura que la Lambda encuentre el m√≥dulo `app.main` y su funci√≥n `handler`.

---

#### 3. ‚úÖ Archivo `.dockerignore`

Al construir im√°genes Docker, incluir archivos innecesarios (como archivos temporales, datos o configuraciones) puede romper el build o aumentar el tama√±o de la imagen.

Se a√±adi√≥ un archivo `.dockerignore` para excluir archivos no necesarios:

```
__pycache__/
*.py[cod]
data/
*.env
.sam/
.aws-sam/
```

Esto evita errores de acceso y mejora la eficiencia del build.

---

#### 4. ‚úÖ `template.yaml` para SAM

`template.yaml` define los recursos que SAM usar√° para simular la arquitectura en local o desplegarla en AWS. Se configura el timeout, el tipo de paquete (`Image`) y el punto de entrada.

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  FastApiFunction:
    Type: AWS::Serverless::Function
    Properties:
      PackageType: Image
      Timeout: 10
      Architectures:
        - x86_64
      Events:
        ApiEvent:
          Type: Api
          Properties:
            Path: /
            Method: get
    Metadata:
      Dockerfile: Dockerfile
      DockerContext: .
      DockerTag: fastapi-lambda
```

As√≠ SAM puede construir y ejecutar la funci√≥n localmente como si estuviera en AWS.

---
### ‚öôÔ∏è ¬øQu√© es AWS SAM?

**AWS SAM (Serverless Application Model)** es un framework open-source para desarrollar, probar y desplegar aplicaciones serverless como AWS Lambda.

> Teor√≠a: SAM usa Docker para emular localmente la ejecuci√≥n de funciones Lambda, incluyendo eventos HTTP, cron, S3, etc. Es ideal para desarrollo sin consumir AWS.

#### ‚úÖ Ventajas principales:
- Probar funciones Lambda **localmente** con `sam local invoke` o `sam local start-api`.
- Evitar consumir la capa gratuita de AWS.
- Facilita el despliegue a producci√≥n con `sam deploy`.

---

### üöÄ C√≥mo probar localmente

# üß™ Pruebas locales de endpoints con SAM + script .sh

Este archivo explica **por qu√© y c√≥mo** automatizar las pruebas de tus endpoints cuando ejecutas tu aplicaci√≥n FastAPI sobre AWS Lambda **usando `sam local start-api`**.

---

## ‚úÖ ¬øPor qu√© hacer pruebas locales?

Cuando desarrollas una API serverless con FastAPI + Lambda, es com√∫n cometer errores de:

- rutas no registradas en `template.yaml`
- errores de CORS o de conexi√≥n
- estructura incorrecta del handler
- falta de par√°metros obligatorios

Automatizar las pruebas con un script `.sh` permite verificar r√°pidamente que todos los endpoints:

- est√°n disponibles
- responden correctamente
- no devuelven errores 403 o 500

---

## üöÄ PRuebas de endpoints localmente

Se crea un script llamado `tests_endpoints.sh` que lanza peticiones `curl` a cada endpoint y muestra claramente:

- la URL probada
- el contenido de la respuesta
- el c√≥digo de estado HTTP

---


## ‚ñ∂Ô∏è C√≥mo ejecutarlo

1. Aseg√∫rate de tener la app corriendo:

```bash
sam local start-api
```

2. En otra terminal, dale permisos al script y ejec√∫talo:

```bash
chmod +x tests/test_all.sh
./tests/test_all.sh
```

---

## ‚úÖ Resultado esperado

```
üîπ Testing / (/)
{"message":"Hello from Lambda"}
Status: 200
-----------------------------
üîπ Testing /healthcheck (/healthcheck)
{"status":"ok"}
Status: 200
-----------------------------
...
```

---

## üß† Conclusi√≥n

El uso de un script `.sh` para pruebas locales con `sam local` es una forma r√°pida, ligera y efectiva de validar el comportamiento de tus endpoints **antes de desplegar a AWS**, asegurando que:

- la configuraci√≥n de rutas est√© correcta
- tu funci√≥n handler funcione como se espera
- la integraci√≥n con Snowflake, S3 y SageMaker se pueda probar paso a paso



```bash
# Construir la imagen
sam build --use-container

# Iniciar emulaci√≥n local de API Gateway
sam local start-api

# Luego acceder a:
http://127.0.0.1:3000/
```

Esto inicia la funci√≥n Lambda con una interfaz local de API Gateway.

---

### ‚úÖ Resultado Final

- Lambda se ejecuta localmente v√≠a Docker y responde a las solicitudes correctamente.
- Se eliminan errores 404.
- No se incurre en costos de uso de AWS para pruebas locales.


### ‚öôÔ∏è Despliegue con AWS CLI

#### üîπ Crear repositorio en ECR:
```bash
aws ecr create-repository --repository-name lead-scoring-api --region your-region
```

#### üîπ Login e imagen Docker:
```bash
aws ecr get-login-password --region your-region | docker login --username AWS --password-stdin your-account-id.dkr.ecr.your-region.amazonaws.com
docker build -t lead-scoring-api .
docker tag lead-scoring-api:latest your-account-id.dkr.ecr.your-region.amazonaws.com/lead-scoring-api:latest
docker push your-account-id.dkr.ecr.your-region.amazonaws.com/lead-scoring-api:latest
```

#### üîπ Crear funci√≥n Lambda desde imagen:
```bash
aws lambda create-function --function-name lead-scoring-api \
  --package-type Image \
  --code ImageUri=your-account-id.dkr.ecr.your-region.amazonaws.com/lead-scoring-api:latest \
  --role arn:aws:iam::your-account-id:role/lambda-execution-role \
  --region your-region --timeout 60 --memory-size 1024
```

#### üîπ API Gateway conectado a Lambda:
```bash
aws apigatewayv2 create-api \
  --name lead-scoring-api \
  --protocol-type HTTP \
  --target arn:aws:lambda:your-region:your-account-id:function:lead-scoring-api
```

#### üîπ Hosting frontend en S3 + CloudFront:
```bash
aws s3 create-bucket --bucket your-frontend-bucket --region your-region
aws s3 website s3://your-frontend-bucket/ --index-document index.html
aws s3 sync ./frontend/build/ s3://your-frontend-bucket/
aws cloudfront create-distribution --origin-domain-name your-frontend-bucket.s3-website-your-region.amazonaws.com
```
Obtener id de distribucion de Cloudfront
```bash
aws cloudfront list-distributions \
  --query "DistributionList.Items[*].{Id:Id,DomainName:DomainName}" \
  --output table
```
---


#### üîπPayload de prueba para AWS Lambda:

```bash
 {
  "version": "2.0",
  "routeKey": "GET /leads/",
  "rawPath": "/leads/",
  "rawQueryString": "",
  "headers": {
    "host": "localhost",
    "user-agent": "aws-cli/2.0",
    "x-forwarded-for": "127.0.0.1"
  },
  "requestContext": {
    "http": {
      "method": "GET",
      "path": "/leads/",
      "protocol": "HTTP/1.1",
      "sourceIp": "127.0.0.1",
      "userAgent": "aws-cli/2.0"
    }
  },
  "isBase64Encoded": false
} 
```

### Habilitar onfiguraci√≥n de sitio web est√°tico en bucket
```bash 
aws s3 website s3://your-frontend-bucket/ --index-document index.html --error-document index.html
```
---

### üîì Permitir acceso p√∫blico al frontend en S3

Para que CloudFront (o cualquier navegador) pueda servir tu frontend almacenado en S3, debes asegurarte de que los archivos sean p√∫blicamente accesibles. Esto se logra aplicando una pol√≠tica de bucket que permita lecturas an√≥nimas.

#### üõ†Ô∏è Comando para aplicar pol√≠tica p√∫blica al bucket

```bash
aws s3api put-bucket-policy --bucket your-frontend-bucket --policy file://<(cat <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::your-frontend-bucket/*"
    }
  ]
}
EOF
)
```

## üöÄ Despliegue de Frontend (Lead Scoring)

Cada vez que se modifica el c√≥digo del frontend, ejecutar los siguientes comandos para actualizar el entorno en producci√≥n (S3 + CloudFront):

```bash
# 1. Generar la build del frontend
npm run build

# 2. Subir la carpeta 'build/' al bucket de S3
aws s3 sync ./build/ s3://your-frontend-bucket --delete

# 3. (Solo si es necesario) Configurar el bucket como sitio web est√°tico
aws s3 website s3://your-frontend-bucket/ --index-document index.html

# 4. Invalidar cach√© de CloudFront para aplicar cambios
aws cloudfront create-invalidation \
  --distribution-id <your-distribution-id> \
  --paths "/*"
```
### Payload para probar AWS Lambda desde consola 

```json
{
  "version": "2.0",
  "routeKey": "GET /healthcheck",
  "rawPath": "/healthcheck",
  "rawQueryString": "",
  "headers": {
    "host": "your-api-id.execute-api.your-region.amazonaws.com",
    "user-agent": "curl/7.64.1",
    "accept": "*/*"
  },
  "requestContext": {
    "http": {
      "method": "GET",
      "path": "/healthcheck",
      "protocol": "HTTP/1.1",
      "sourceIp": "127.0.0.1",
      "userAgent": "curl/7.64.1"
    }
  },
  "isBase64Encoded": false
}
```

## Integraci√≥n Snowflake con AWS S3 usando Storage Integration y rol IAM

Este procedimiento describe c√≥mo configurar un bucket S3 con permisos para que Snowflake pueda cargar datos mediante Snowpipe usando una Storage Integration segura.

### 1. Crear bucket S3

Crea un bucket en AWS S3 donde se subir√°n los archivos, por ejemplo:

```bash
aws s3api create-bucket --bucket your-bucket-name --region your-region --create-bucket-configuration LocationConstraint=your-region
````

### 2. Crear rol IAM en AWS con permisos al bucket

* Crea un rol IAM llamado, por ejemplo, `SnowflakeS3AccessRole`.
* Asigna una pol√≠tica de confianza temporal para poder crear el rol (luego se actualizar√°).
* A√±ade una pol√≠tica inline con permisos:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:GetObject", "s3:ListBucket"],
      "Resource": [
        "arn:aws:s3:::your-bucket-name",
        "arn:aws:s3:::your-bucket-name/*"
      ]
    }
  ]
}
```

### 3. Crear Storage Integration en Snowflake

Ejecuta el siguiente SQL en Snowflake, reemplazando `<ROL_ARN>` por el ARN completo del rol creado en AWS:

```sql
CREATE OR REPLACE STORAGE INTEGRATION s3_leads_integration
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = S3
  ENABLED = TRUE
  STORAGE_AWS_ROLE_ARN = '<ROL_ARN>'
  STORAGE_ALLOWED_LOCATIONS = ('s3://your-bucket-name/');
```

### 4. Obtener par√°metros para la pol√≠tica de confianza

Ejecuta:

```sql
DESC INTEGRATION s3_leads_integration;
```

Anota los valores:

* `STORAGE_AWS_IAM_USER_ARN`
* `STORAGE_AWS_EXTERNAL_ID`

### 5. Actualizar pol√≠tica de confianza en AWS IAM

Edita la pol√≠tica de confianza del rol `SnowflakeS3AccessRole` para que luzca as√≠, usando los valores obtenidos:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "<STORAGE_AWS_IAM_USER_ARN>"
      },
      "Action": "sts:AssumeRole",
      "Condition": {
        "StringEquals": {
          "sts:ExternalId": "<STORAGE_AWS_EXTERNAL_ID>"
        }
      }
    }
  ]
}
```

### 6. Crear stage en Snowflake

```sql
CREATE OR REPLACE STAGE leads_internal_stage
  URL = 's3://your-bucket-name/'
  STORAGE_INTEGRATION = s3_leads_integration
  FILE_FORMAT = json_as_variant;
```




### üß† Servicios y funcionalidades integradas

- **Snowflake**: Carga de datos, funciones de scoring, tareas programadas.
- **AWS Lambda**: Backend sin servidores.
- **API Gateway**: Exposici√≥n de endpoints p√∫blicos.
- **Amazon S3 + CloudFront**: Hosting global del frontend.
- **AWS SageMaker**: Scoring predictivo de leads.
- **AWS Athena**: Conteo de registros desde datos crudos en S3.
- **AWS CloudWatch**: Monitoreo de logs.
- **PowerCurve (futuro)**: Considerado para administraci√≥n avanzada de usuarios.

